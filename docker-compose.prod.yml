
# Production configuration
# without reverse proxy (ports exposed directly)
#
# Usage:
#   1. Copy .env.prod.example to .env.prod and fill in values:
#      cp .env.prod.example .env.prod
#   2. Run: docker-compose -f docker-compose.prod.yml up -d

services:

  app:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: arachne_fullstack_backend
    user: root
    env_file:
      - .env.prod
      - ./backend/.env
    environment:
      - DEBUG=false
      - ENVIRONMENT=production
      - POSTGRES_HOST=db
      - REDIS_HOST=redis
    command: uvicorn app.main:app --host 0.0.0.0 --port 8550 --workers 4
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - backend-internal
    ports:
      - "8550:8550"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      python_sandbox:
        condition: service_completed_successfully
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8550/api/v1/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5


  db:
    image: postgres:18-alpine
    container_name: arachne_fullstack_db
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-arachne_fullstack}
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    # NO external ports - only accessible within backend-internal network
    networks:
      - backend-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: arachne_fullstack_redis
    command: redis-server --requirepass ${REDIS_PASSWORD:?REDIS_PASSWORD is required}
    # NO external ports - only accessible within backend-internal network
    volumes:
      - ./redis_data:/data
    networks:
      - backend-internal
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:


  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: arachne_fullstack_celery_worker
    command: celery -A app.worker.celery_app worker --loglevel=warning --concurrency=4
    env_file:
      - .env.prod
      - ./backend/.env
    environment:
      - DEBUG=false
      - POSTGRES_HOST=db
      - REDIS_HOST=redis
    networks:
      - backend-internal
    depends_on:
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    restart: unless-stopped
    # deploy:
    #   replicas: 2


  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: arachne_fullstack_celery_beat
    command: celery -A app.worker.celery_app beat --loglevel=warning
    env_file:
      - .env.prod
      - ./backend/.env
    environment:
      - DEBUG=false
      - REDIS_HOST=redis
    networks:
      - backend-internal
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  flower:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: arachne_fullstack_flower
    command: celery -A app.worker.celery_app flower --port=5555
    env_file:
      - .env.prod
      - ./backend/.env
    environment:
      - DEBUG=false
      - REDIS_HOST=redis
      - FLOWER_BASIC_AUTH=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:?FLOWER_PASSWORD is required}
    networks:
      - backend-internal
    ports:
      - "5555:5555"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped


  s3:
    image: minio/minio:latest
    container_name: arachne_fullstack_s3
    command: server /data --console-address ":9001"
    env_file:
      - .env.prod
    ports:
      - "9055:9000"
      - "9011:9001"
    volumes:
      - ./s3_data:/data
    networks:
      - backend-internal
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  python_sandbox:
    build:
      context: .
      dockerfile: Dockerfile.sandbox
    image: python-sandbox:latest
    container_name: arachne_fullstack_python_sandbox
    volumes:
      - ./python-file-store:/filestore
    entrypoint: ["echo", "Sandbox image built successfully"]
    networks:
      - backend-internal
    restart: "no"

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL:-ws://localhost:8550}
        - NEXT_PUBLIC_S3_HOST=${NEXT_PUBLIC_S3_HOST:-}
    container_name: arachne_fullstack_frontend
    environment:
      - NODE_ENV=production
      - BACKEND_URL=http://app:8550
      - BACKEND_WS_URL=ws://app:8550
      - SECURE_COOKIES=${SECURE_COOKIES:-false}
      - INTERNAL_API_KEY=${INTERNAL_API_KEY}
    networks:
      - backend-internal
    ports:
      - "3552:3552"
    depends_on:
      - app
    restart: unless-stopped

networks:
  backend-internal:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  s3_data:
  python-file-store:
